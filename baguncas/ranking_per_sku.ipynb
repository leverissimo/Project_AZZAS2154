{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d395fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Froms\n",
    "from src.gcpUtils.auth import getCredentials\n",
    "from src.gcpUtils.bigQuery import pandasToBq, tableToPandas\n",
    "from src.gcpUtils.google_storage_manager import *\n",
    "\n",
    "cred = getCredentials(\"../bd/planejamento-animale-292719-296d49ccdea6.json\")\n",
    "# --- 1. Constantes de Negócio ---\n",
    "\n",
    "# Caminho para seu arquivo de distâncias\n",
    "ARQUIVO_DISTANCIAS = '../dados/distancias_todas_combinacoes_BIDIRECIONAL.csv'\n",
    "\n",
    "# Constantes para a fórmula de Leadtime Teórico\n",
    "K = 3\n",
    "K_prime = 6\n",
    "p = 6\n",
    "q = 4\n",
    "C = 0.0225\n",
    "alpha = 2\n",
    "\n",
    "ARQUIVO_JSON_FILIAIS = '../dados/filiais_inferior_30.json'\n",
    "DATA_ANALISE = '2025-08-16'  # Formato AAAA-MM-DD\n",
    "TABELA_BIGQUERY = 'planejamento-animale-292719.checklists_rollout.ANIMALE_checklist'\n",
    "PATH_CREDENCAIS = '../bd/planejamento-animale-292719-296d49ccdea6.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a81c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    print(f\"Carregando filiais do arquivo: {ARQUIVO_JSON_FILIAIS}...\")\n",
    "    \n",
    "    with open(ARQUIVO_JSON_FILIAIS, 'r', encoding='utf-8') as f:\n",
    "        dados_filiais = json.load(f)\n",
    "        \n",
    "    df_filiais = pd.DataFrame(dados_filiais)\n",
    "    \n",
    "    lista_nomes_filiais = df_filiais['FILIAL'].unique().tolist()\n",
    "    \n",
    "    if not lista_nomes_filiais:\n",
    "        print(\"Atenção: Nenhuma filial foi encontrada no arquivo JSON.\")\n",
    "    else:\n",
    "        print(f\"Sucesso. {len(lista_nomes_filiais)} filiais únicas encontradas.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo JSON não encontrado em '{ARQUIVO_JSON_FILIAIS}'\")\n",
    "    lista_nomes_filiais = []\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo JSON: {e}\")\n",
    "    lista_nomes_filiais = []\n",
    "\n",
    "\n",
    "# --- Montar e Executar a Query ---\n",
    "\n",
    "if lista_nomes_filiais:\n",
    "    \n",
    "    # Ex: Transforma ['Filial A', 'Filial B'] em \"('Filial A', 'Filial B')\"\n",
    "    filiais_para_query = \"','\".join(lista_nomes_filiais)\n",
    "    filiais_para_query = f\"('{filiais_para_query}')\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT SKU, FILIAL, VELOCIDADE_VENDA, ALVO, PRESENTE, TRANSITO, \n",
    "        EST_TOTAL, CONT_RUPTURA, CONT_FALTA, CONT_EXCESSO, VOLUME_EXCESSO, REGULADOR, EST_DISP\n",
    "        FROM {TABELA_BIGQUERY}\n",
    "        WHERE FILIAL IN {filiais_para_query}\n",
    "        AND DATA = '{DATA_ANALISE}'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Buscar os dados ---\n",
    "        \n",
    "        print(\"Executando consulta no BigQuery...\")\n",
    "        df_resultado = tableToPandas(query, 'planejamento-animale-292719', cred)\n",
    "        \n",
    "        print(\"\\n--- Resultado da Consulta ---\")\n",
    "        if df_resultado.empty:\n",
    "            print(\"A consulta não retornou dados.\")\n",
    "        else:\n",
    "            print(df_resultado)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao executar a consulta no BigQuery: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nAnálise não executada pois nenhuma filial foi carregada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0257b1",
   "metadata": {},
   "source": [
    "# Coisa que a Chacára pediu para fazer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar uma pasta para resultados\n",
    "if not os.path.exists('resultados'):\n",
    "    os.makedirs('resultados')\n",
    "\n",
    "path_filtragem = 'dataframes/'\n",
    "# --- Processar os dados ---\n",
    "\n",
    "# add Centro de Distribuição\n",
    "df_estoque_dia = df_resultado.copy()\n",
    "df_cd_estoque = df_estoque_dia.groupby('SKU', as_index=False)['REGULADOR'].first()\n",
    "df_cd_estoque['FILIAL'] = \"CENTRO DE DISTRIBUICAO\".strip()\n",
    "df_cd_estoque = df_cd_estoque.rename(columns={'REGULADOR': 'VOLUME_EXCESSO'})\n",
    "    \n",
    "df_estoque_completo = pd.concat([df_estoque_dia, df_cd_estoque], ignore_index=True)\n",
    "\n",
    "df_estoque_completo.to_csv('resultados/dados_filiais.csv', index=False)\n",
    "\n",
    "# filtragem para filiais específicas de um csv\n",
    "for arquivo in os.listdir(path_filtragem):\n",
    "        caminho_arquivo = os.path.join(path_filtragem, arquivo)\n",
    "        df_filtragem = pd.read_csv(caminho_arquivo)\n",
    "        if arquivo.endswith('.csv'):\n",
    "            # todas as opções, contadas uma vez, da coluna Filial_A e Filial_B\n",
    "            filiais_especificas = pd.unique(df_filtragem[['Filial_A', 'Filial_B']].values.ravel('K')).tolist()\n",
    "            \n",
    "            df_filtrado = df_estoque_completo[df_estoque_completo['FILIAL'].isin(filiais_especificas)]\n",
    "            \n",
    "            nome_arquivo_saida = f'resultados/dados_filiais_filtradas_{arquivo}'\n",
    "            df_filtrado.to_csv(nome_arquivo_saida, index=False)\n",
    "            print(f\"Dados filtrados salvos em: {nome_arquivo_saida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eded9f",
   "metadata": {},
   "source": [
    "# ------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a829d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Bloco 1: Funções de Carregamento e Auxiliares\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def carregar_matriz_distancia(caminho_csv):\n",
    "    \"\"\"\n",
    "    Carrega o CSV de distâncias, selecionando apenas as colunas necessárias.\n",
    "    Retorna um DataFrame vazio em caso de erro.\n",
    "    \"\"\"\n",
    "    colunas_necessarias = ['Filial_A', 'Filial_B', 'Distancia_km']\n",
    "    try:\n",
    "        df_dist = pd.read_csv(\n",
    "            caminho_csv,\n",
    "            usecols=colunas_necessarias\n",
    "        )\n",
    "        print(f\"Matriz de distâncias carregada com {len(df_dist)} combinações.\")\n",
    "        return df_dist\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo CSV não encontrado em '{caminho_csv}'\")\n",
    "        return pd.DataFrame(columns=colunas_necessarias)\n",
    "    except ValueError as e:\n",
    "        # Erro comum se uma das colunas (usecols) não existir no CSV\n",
    "        print(f\"Erro ao carregar CSV (verifique as colunas): {e}\")\n",
    "        return pd.DataFrame(columns=colunas_necessarias)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao carregar CSV: {e}\")\n",
    "        return pd.DataFrame(columns=colunas_necessarias)\n",
    "\n",
    "\n",
    "def _preparar_dados(df_estoque, df_distancias):\n",
    "    \"\"\"\n",
    "    (Auxiliar) Limpa e padroniza os DataFrames de entrada.\n",
    "    Cria cópias para evitar SettingWithCopyWarning.\n",
    "    \"\"\"\n",
    "    df_estoque_proc = df_estoque.copy()\n",
    "    df_dist_proc = df_distancias.copy()\n",
    "\n",
    "    # Padroniza colunas de filiais\n",
    "    df_estoque_proc['FILIAL'] = df_estoque_proc['FILIAL'].astype(str).str.strip()\n",
    "    df_dist_proc['Filial_A'] = df_dist_proc['Filial_A'].astype(str).str.strip()\n",
    "    df_dist_proc['Filial_B'] = df_dist_proc['Filial_B'].astype(str).str.strip()\n",
    "\n",
    "    # Renomeia colunas de estoque, se necessário\n",
    "    # if 'PRESENTE' in df_estoque_proc.columns:\n",
    "    #     df_estoque_proc = df_estoque_proc.rename(columns={'PRESENTE': 'EST_DISP'})\n",
    "\n",
    "    return df_estoque_proc, df_dist_proc\n",
    "\n",
    "\n",
    "def _identificar_fontes_destinos(df_estoque):\n",
    "    \"\"\"\n",
    "    (Auxiliar) Calcula a demanda líquida e filtra as lojas-fonte e lojas-destino.\n",
    "    \"\"\"\n",
    "    # --- 1. Calcular Demanda Líquida ---\n",
    "    # Garante que a demanda nunca seja negativa\n",
    "    df_estoque['DEMANDA_LIQUIDA'] = np.maximum(\n",
    "        0,\n",
    "        df_estoque['ALVO'].fillna(0) - df_estoque['EST_TOTAL'].fillna(0)\n",
    "    )\n",
    "\n",
    "    # --- 2. Identificar TODAS as Fontes ---\n",
    "    df_fontes = df_estoque[\n",
    "        df_estoque['VOLUME_EXCESSO'].fillna(0) > 0\n",
    "    ][['SKU', 'FILIAL', 'VOLUME_EXCESSO']].rename(columns={'FILIAL': 'FILIAL_FONTE'})\n",
    "\n",
    "    # --- 3. Identificar TODOS os Destinos ---\n",
    "    criterio_demanda = (df_estoque['DEMANDA_LIQUIDA'] > 0)\n",
    "    criterio_ruptura = (df_estoque['CONT_RUPTURA'] == 1)\n",
    "    criterio_falta = (df_estoque['CONT_FALTA'] == 1)\n",
    "    \n",
    "    df_destinos = df_estoque[criterio_demanda | criterio_ruptura | criterio_falta][[\n",
    "        'SKU', 'FILIAL', 'DEMANDA_LIQUIDA',\n",
    "        'CONT_RUPTURA', 'CONT_FALTA', 'VELOCIDADE_VENDA'\n",
    "    ]].rename(columns={'FILIAL': 'FILIAL_DESTINO'})\n",
    "\n",
    "    return df_fontes, df_destinos\n",
    "\n",
    "\n",
    "def _criar_pares_transferencia(df_fontes, df_destinos, df_distancias):\n",
    "    \"\"\"\n",
    "    (Auxiliar) Cria os pares N x N (SKU/Fonte/Destino) e anexa as distâncias.\n",
    "    \"\"\"\n",
    "    # --- 4. Criar Pares de Transferência (N x N) ---\n",
    "    df_pares = pd.merge(df_fontes, df_destinos, on='SKU')\n",
    "    \n",
    "    # Remove transferências para a própria loja\n",
    "    df_pares = df_pares[df_pares['FILIAL_FONTE'] != df_pares['FILIAL_DESTINO']]\n",
    "    \n",
    "    if df_pares.empty:\n",
    "        print(\"Nenhum par de transferência válido (Fonte != Destino) foi encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 5. Juntar Distâncias ---\n",
    "    df_ranking = pd.merge(\n",
    "        df_pares,\n",
    "        df_distancias,\n",
    "        left_on=['FILIAL_FONTE', 'FILIAL_DESTINO'],\n",
    "        right_on=['Filial_A', 'Filial_B']\n",
    "    )\n",
    "\n",
    "    if df_ranking.empty:\n",
    "        print(\"Erro: Nenhum par de transferência encontrou uma distância correspondente no CSV.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    print(f\"\\n--- {len(df_ranking)} Pares de transferência encontrados ---\")\n",
    "    return df_ranking\n",
    "\n",
    "\n",
    "def _calcular_scores_ranking(df_ranking):\n",
    "    \"\"\"\n",
    "    (Auxiliar) Aplica a fórmula de negócio para calcular os scores de ranking.\n",
    "    \"\"\"\n",
    "    df_calc = df_ranking.copy()\n",
    "\n",
    "    # --- 6. Cálculo dos Fatores da Fórmula ---\n",
    "    df_calc['FATOR_PREFERENCIA'] = np.where(\n",
    "        df_calc['FILIAL_FONTE'] == \"CENTRO DE DISTRIBUICAO\",\n",
    "        alpha,\n",
    "        1\n",
    "    )\n",
    "    k_series = np.where(\n",
    "        df_calc['FILIAL_DESTINO'].astype(str).str.strip() == \"CENTRO DE DISTRIBUICAO\",\n",
    "        K_prime,\n",
    "        K\n",
    "    )\n",
    "\n",
    "    # Fator Logística\n",
    "    df_calc['LEADTIME'] = C * df_calc['Distancia_km']\n",
    "    df_calc['CUSTO_FRETE'] = k_series * df_calc['Distancia_km']\n",
    "    fator_logistica = (1 / (df_calc['LEADTIME'] + 1)) + (1 / (df_calc['CUSTO_FRETE'] + 1))\n",
    "\n",
    "    # Fator Demanda\n",
    "    cont_ruptura = df_calc['CONT_RUPTURA'].fillna(0)\n",
    "    cont_falta = df_calc['CONT_FALTA'].fillna(0)\n",
    "    fator_demanda = (cont_ruptura * p) + (cont_falta * q)\n",
    "\n",
    "    # velocidade_venda = df_calc['VELOCIDADE_VENDA'].fillna(0)\n",
    "    \n",
    "\n",
    "    # --- 7. Ranking Bruto e Final ---\n",
    "    df_calc['RANKING_TRANSFERENCIA_BRUTO'] = (\n",
    "        fator_logistica * fator_demanda * df_calc['FATOR_PREFERENCIA']\n",
    "    )\n",
    "\n",
    "    # Quantidade real a ser transferida é o mínimo entre o excesso e a necessidade\n",
    "    df_calc['QTD_A_TRANSFERIR'] = np.minimum(\n",
    "        df_calc['VOLUME_EXCESSO'], df_calc['DEMANDA_LIQUIDA']\n",
    "    )\n",
    "\n",
    "    # Zera o ranking se não houver o que transferir (sem excesso ou sem demanda)\n",
    "    df_calc['RANKING_TRANSFERENCIA'] = df_calc['RANKING_TRANSFERENCIA_BRUTO']\n",
    "    df_calc.loc[df_calc['QTD_A_TRANSFERIR'] == 0, 'RANKING_TRANSFERENCIA'] = 0\n",
    "\n",
    "    return df_calc\n",
    "\n",
    "\n",
    "def _finalizar_ranking(df_ranking_calculado):\n",
    "    \"\"\"\n",
    "    (Auxiliar) Ordena, seleciona e limpa as colunas para o resultado final.\n",
    "    \"\"\"\n",
    "    # --- 8. Limpar e Ordenar ---\n",
    "    df_resultado = df_ranking_calculado.sort_values(by='RANKING_TRANSFERENCIA', ascending=False)\n",
    "\n",
    "    colunas_finais = [\n",
    "        'SKU',\n",
    "        'FILIAL_FONTE',\n",
    "        'FILIAL_DESTINO',\n",
    "        'RANKING_TRANSFERENCIA',\n",
    "        'QTD_A_TRANSFERIR',\n",
    "        'VELOCIDADE_VENDA',\n",
    "        'CONT_RUPTURA',\n",
    "        'CONT_FALTA',\n",
    "        'VOLUME_EXCESSO',\n",
    "        'DEMANDA_LIQUIDA',\n",
    "        'Distancia_km',\n",
    "        'FATOR_PREFERENCIA',\n",
    "        'LEADTIME',\n",
    "        'CUSTO_FRETE'\n",
    "    ]\n",
    "\n",
    "    # Garante que apenas colunas existentes sejam selecionadas\n",
    "    colunas_existentes = [col for col in colunas_finais if col in df_resultado.columns]\n",
    "\n",
    "    print(f\"  Ranking global N x N calculado.\")\n",
    "    transferencias_sugeridas = df_resultado[df_resultado['RANKING_TRANSFERENCIA'] > 0].shape[0]\n",
    "    print(f\"  Total de transferências possíveis sugeridas: {transferencias_sugeridas}\")\n",
    "\n",
    "    return df_resultado[colunas_existentes].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def encontrar_melhores_fontes_para_sku_destino(df_ranking_global, sku_desejado):\n",
    "    \"\"\"\n",
    "    Para um SKU específico, encontra a *única* melhor filial-fonte\n",
    "    para *cada* filial-destino que o demanda.\n",
    "\n",
    "    Garante que cada destino receba de apenas uma fonte (a de maior ranking).\n",
    "    \"\"\"\n",
    "    if df_ranking_global.empty:\n",
    "        print(\"DataFrame de ranking global está vazio.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sku_desejado_limpo = str(sku_desejado).strip()\n",
    "    df_sku = df_ranking_global[\n",
    "        df_ranking_global['SKU'].astype(str).str.strip() == sku_desejado_limpo\n",
    "    ]\n",
    "\n",
    "    if df_sku.empty:\n",
    "        print(f\"Nenhuma transferência encontrada para o SKU: {sku_desejado_limpo}\")\n",
    "        return pd.DataFrame(columns=df_ranking_global.columns)\n",
    "\n",
    "    print(f\"\\nAnalisando {len(df_sku)} pares possíveis para o SKU {sku_desejado_limpo}...\")\n",
    "\n",
    "    df_best_source_per_dest = df_sku.groupby('FILIAL_DESTINO').first()\n",
    "\n",
    "    df_best_source_per_dest = df_best_source_per_dest.reset_index()\n",
    "    df_best_source_per_dest = df_best_source_per_dest.sort_values(\n",
    "        by='RANKING_TRANSFERENCIA',\n",
    "        ascending=False\n",
    "    )\n",
    "\n",
    "    print(f\"Encontradas {len(df_best_source_per_dest)} transferências ótimas \"\n",
    "          f\"(uma para cada destino do SKU).\")\n",
    "\n",
    "    return df_best_source_per_dest\n",
    "# ---------------------------------------------------------------------------\n",
    "# Bloco 2: Funções Principais de Orquestração e Análise\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def calcular_ranking_global_nxn(df_estoque, df_distancias):\n",
    "    \"\"\"\n",
    "    Orquestra o cálculo completo do ranking N x N de transferências.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df_estoque (pd.DataFrame): DataFrame com dados de estoque, demanda, etc.\n",
    "    - df_distancias (pd.DataFrame): DataFrame com distâncias (Filial_A, Filial_B, Distancia_km).\n",
    "    - alpha (float): Peso para \"CENTRO DE DISTRIBUICAO\".\n",
    "    - C (float): Constante para cálculo de LEADTIME.\n",
    "    - K (float): Constante para cálculo de CUSTO_FRETE.\n",
    "    - p (float): Peso para CONT_RUPTURA.\n",
    "    - q (float): Peso para CONT_FALTA.\n",
    "    \n",
    "    Retorna:\n",
    "    - (pd.DataFrame): DataFrame ordenado com todas as transferências possíveis.\n",
    "    \"\"\"\n",
    "    if df_estoque.empty or df_distancias.empty:\n",
    "        print(\"Erro: Dados de estoque ou distâncias estão vazios. Encerrando.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Bloco 1: Preparação\n",
    "    df_estoque_proc, df_dist_proc = _preparar_dados(df_estoque, df_distancias)\n",
    "\n",
    "    # Bloco 2: Identificar Atores (Fontes e Destinos)\n",
    "    df_fontes, df_destinos = _identificar_fontes_destinos(df_estoque_proc)\n",
    "    \n",
    "    if df_fontes.empty:\n",
    "        print(\"Nenhuma loja-fonte com estoque em excesso foi encontrada.\")\n",
    "        return pd.DataFrame()\n",
    "    if df_destinos.empty:\n",
    "        print(\"Nenhuma loja-destino com demanda encontrada.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Bloco 3: Criar Pares\n",
    "    df_ranking_inicial = _criar_pares_transferencia(df_fontes, df_destinos, df_dist_proc)\n",
    "    \n",
    "    if df_ranking_inicial.empty:\n",
    "        print(\"Cálculo interrompido, nenhum par de transferência válido foi encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Bloco 4: Calcular Scores\n",
    "    df_ranking_calculado = _calcular_scores_ranking(\n",
    "        df_ranking_inicial\n",
    "    )\n",
    "\n",
    "    # Bloco 5: Finalizar\n",
    "    df_resultado_final = _finalizar_ranking(df_ranking_calculado)\n",
    "\n",
    "    return df_resultado_final\n",
    "\n",
    "\n",
    "def encontrar_melhor_match_para_sku(df_ranking_global, sku_desejado):\n",
    "    \"\"\"\n",
    "    Filtra o ranking global (já ordenado) para encontrar a melhor opção \n",
    "    para um SKU específico.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df_ranking_global (pd.DataFrame): O DataFrame retornado por `calcular_ranking_global_nxn`.\n",
    "    - sku_desejado (str/int): O SKU a ser buscado.\n",
    "\n",
    "    Retorna:\n",
    "    - (pd.DataFrame): Um DataFrame com a melhor linha (top 1) para o SKU, \n",
    "                      ou um DataFrame vazio se o SKU não for encontrado.\n",
    "    \"\"\"\n",
    "    if df_ranking_global.empty:\n",
    "        print(\"DataFrame de ranking global está vazio.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    sku_desejado_limpo = str(sku_desejado).strip()\n",
    "    \n",
    "    # Filtra pelo SKU. Como o DF já está ordenado, .head(1) pega o melhor.\n",
    "    df_sku = df_ranking_global[\n",
    "        df_ranking_global['SKU'].astype(str).str.strip() == sku_desejado_limpo\n",
    "    ]\n",
    "\n",
    "    if df_sku.empty:\n",
    "        print(f\"Nenhuma transferência encontrada para o SKU: {sku_desejado_limpo}\")\n",
    "        return pd.DataFrame(columns=df_ranking_global.columns)\n",
    "\n",
    "    return df_sku.head(1)\n",
    "\n",
    "\n",
    "def encontrar_melhor_match_para_todos_skus(df_ranking_global):\n",
    "    \"\"\"\n",
    "    Agrupa o ranking global para encontrar a *única* melhor transferência \n",
    "    (maior ranking) para *cada* SKU.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df_ranking_global (pd.DataFrame): O DataFrame retornado por `calcular_ranking_global_nxn`.\n",
    "\n",
    "    Retorna:\n",
    "    - (pd.DataFrame): Um DataFrame onde cada linha é o melhor match para um SKU.\n",
    "    \"\"\"\n",
    "    if df_ranking_global.empty:\n",
    "        print(\"DataFrame de ranking global está vazio.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"\\nEncontrando o melhor match para {df_ranking_global['SKU'].nunique()} SKUs únicos...\")\n",
    "\n",
    "    # Como o df_ranking_global JÁ ESTÁ ORDENADO pelo ranking,\n",
    "    # .first() pega a linha com o maior ranking para cada grupo de SKU.\n",
    "    df_best_matches = df_ranking_global.groupby('SKU').first()\n",
    "\n",
    "    # O groupby torna 'SKU' o índice. Vamos resetar para ser uma coluna.\n",
    "    df_best_matches = df_best_matches.reset_index()\n",
    "\n",
    "    # Re-ordenar a lista final pela prioridade geral\n",
    "    df_best_matches = df_best_matches.sort_values(by='RANKING_TRANSFERENCIA', ascending=False)\n",
    "\n",
    "    print(f\"Melhores matches encontrados.\")\n",
    "    return df_best_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    print(\"--- ETAPA 1: Preparando Dados (Lojas + CD) ---\")\n",
    "    \n",
    "    df_distancias_total = carregar_matriz_distancia(ARQUIVO_DISTANCIAS)\n",
    "    df_estoque_dia = df_resultado.copy()\n",
    "\n",
    "    # Limpa a coluna FILIAL original\n",
    "    df_estoque_dia['FILIAL'] = df_estoque_dia['FILIAL'].astype(str).str.strip()\n",
    "\n",
    "    df_cd_estoque = df_estoque_dia.groupby('SKU', as_index=False)['REGULADOR'].first()\n",
    "    df_cd_estoque['FILIAL'] = \"CENTRO DE DISTRIBUICAO\".strip()\n",
    "    df_cd_estoque = df_cd_estoque.rename(columns={'REGULADOR': 'VOLUME_EXCESSO'})\n",
    "    \n",
    "    df_estoque_completo = pd.concat([df_estoque_dia, df_cd_estoque], ignore_index=True)\n",
    "\n",
    "    # --- FIM DO FIX 1 ---\n",
    "\n",
    "    print(\"\\n--- ETAPA 2: Calculando Ranking Global N-para-N ---\")\n",
    "\n",
    "    # --- FIX 2 (CORREÇÃO DO TYPEERROR): Passando todos os parâmetros ---\n",
    "    df_ranking_global = calcular_ranking_global_nxn(\n",
    "        df_estoque_completo, \n",
    "        df_distancias_total,\n",
    "    )\n",
    "    # --- FIM DO FIX 2 ---\n",
    "    \n",
    "    if not df_ranking_global.empty:\n",
    "        \n",
    "        # Filtro para remover rankings 0 (conforme solicitado)\n",
    "        print(f\"Ranking N-N calculado. Total de pares válidos (bruto): {len(df_ranking_global)}\")\n",
    "        df_ranking_global = df_ranking_global[df_ranking_global['RANKING_TRANSFERENCIA'] > 0].copy()\n",
    "        print(f\"Total de pares após filtro (Ranking > 0): {len(df_ranking_global)}\")\n",
    "\n",
    "        print(\"\\n--- ETAPA 3: Testando a Função 1 (Match para SKU específico) ---\")\n",
    "        sku = \"25.34.2744-0101-TAM_2\" # SKU de teste\n",
    "        \n",
    "        df_melhor_match_sku = encontrar_melhor_match_para_sku(df_ranking_global, sku)\n",
    "        \n",
    "        if not df_melhor_match_sku.empty:\n",
    "            print(f\"Melhor match encontrado para {sku}:\")\n",
    "            print(df_melhor_match_sku.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "        else:\n",
    "            print(f\"Nenhum match encontrado para {sku}\")\n",
    "        \n",
    "        print(\"\\n--- ETAPA 4: Testando a Função 2 (Melhor match para TODOS os SKUs) ---\")\n",
    "        df_melhores_matches_todos_skus = encontrar_melhor_match_para_todos_skus(df_ranking_global)\n",
    "        \n",
    "        print(\"Melhores matches encontrados (um por SKU):\")\n",
    "        print(df_melhores_matches_todos_skus.head().to_markdown(index=False, floatfmt=\".4f\"))\n",
    "        \n",
    "        output_path_etapa4 = \"melhores_matches_todos_skus.xlsx\"\n",
    "        df_melhores_matches_todos_skus.to_excel(output_path_etapa4, index=False)\n",
    "        print(f\"Resultado da Etapa 4 salvo em: {output_path_etapa4}\")\n",
    "\n",
    "        print(f\"\\n--- ETAPA 5: Testando a Função 3 (Melhores fontes p/ destinos do SKU: {sku}) ---\")\n",
    "        df_melhores_fontes_sku = encontrar_melhores_fontes_para_sku_destino(df_ranking_global, sku)\n",
    "\n",
    "        if not df_melhores_fontes_sku.empty:\n",
    "            print(f\"Melhores fontes para CADA destino do SKU {sku}:\")\n",
    "            print(df_melhores_fontes_sku.head().to_markdown(index=False, floatfmt=\".4f\"))\n",
    "            \n",
    "            output_path_etapa5 = f\"melhores_fontes_sku_{sku}.xlsx\"\n",
    "            df_melhores_fontes_sku.to_excel(output_path_etapa5, index=False)\n",
    "            print(f\"Resultado da Etapa 5 salvo em: {output_path_etapa5}\")\n",
    "        else:\n",
    "            print(f\"Nenhuma fonte/destino encontrado para {sku}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nCálculo do ranking N-para-N não gerou resultados. Funções de match não executadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44283741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_debug_sku(sku_desejado, df_estoque_completo, df_ranking_global):\n",
    "    \"\"\"\n",
    "    Exibe um relatório de debug detalhado para um único SKU,\n",
    "    mostrando fontes, destinos e todos os parâmetros de cálculo.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"INICIANDO DEBUG PARA O SKU: {sku_desejado}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # --- 1. Limpeza e Validação ---\n",
    "    sku_desejado = str(sku_desejado).strip()\n",
    "    \n",
    "    df_sku_data = df_estoque_completo[\n",
    "        df_estoque_completo['SKU'].astype(str).str.strip() == sku_desejado\n",
    "    ].copy()\n",
    "    \n",
    "    if df_sku_data.empty:\n",
    "        print(f\"ERRO: SKU '{sku_desejado}' não foi encontrado no DataFrame de estoque.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Exibir Fontes (Quem TEM o SKU) ---\n",
    "    print(\"\\n## 1. FONTES (Quem tem este SKU)\")\n",
    "    df_fontes = df_sku_data[df_sku_data['VOLUME_EXCESSO'].fillna(0) > 0]\n",
    "    \n",
    "    if df_fontes.empty:\n",
    "        print(\"Nenhuma filial fonte encontrada com excesso/estoque deste SKU.\")\n",
    "    else:\n",
    "        print(df_fontes[['FILIAL', 'VOLUME_EXCESSO']].to_markdown(index=False))\n",
    "\n",
    "    # --- 3. Exibir Destinos (Quem PRECISA do SKU) ---\n",
    "    print(\"\\n## 2. DESTINOS (Quem precisa deste SKU)\")\n",
    "    \n",
    "    if 'DEMANDA_LIQUIDA' not in df_sku_data.columns:\n",
    "        print(\"  (Calculando 'DEMANDA_LIQUIDA' para o debug...)\")\n",
    "        df_sku_data['DEMANDA_LIQUIDA'] = np.maximum(0, df_sku_data['ALVO'].fillna(0) - df_sku_data['EST_DISP'].fillna(0))\n",
    "\n",
    "    df_destinos = df_sku_data[\n",
    "        (df_sku_data['DEMANDA_LIQUIDA'].fillna(0) > 0) | \n",
    "        (df_sku_data['CONT_RUPTURA'].fillna(0) == 1)\n",
    "    ]\n",
    "    \n",
    "    if df_destinos.empty:\n",
    "        print(\"Nenhuma filial destino encontrada com demanda para este SKU.\")\n",
    "    else:\n",
    "        cols_destino = ['FILIAL', 'DEMANDA_LIQUIDA', 'CONT_RUPTURA', 'CONT_FALTA', 'VELOCIDADE_VENDA']\n",
    "        cols_destino_existentes = [col for col in cols_destino if col in df_destinos.columns]\n",
    "        print(df_destinos[cols_destino_existentes].to_markdown(index=False, floatfmt=\".2f\"))\n",
    "\n",
    "    # --- 4. Exibir Cálculos (O \"Matching\" N-para-N) ---\n",
    "    print(\"\\n## 3. CÁLCULO DE RANKING (Todos os Matches Possíveis)\")\n",
    "    \n",
    "    # Filtra o ranking global (que agora tem 'VELOCIDADE_VENDA')\n",
    "    df_ranking_sku = df_ranking_global[\n",
    "        df_ranking_global['SKU'].astype(str).str.strip() == sku_desejado\n",
    "    ]\n",
    "    \n",
    "    if df_ranking_sku.empty:\n",
    "        print(\"Nenhum match (Fonte -> Destino) foi encontrado ou calculado para este SKU.\")\n",
    "    else:\n",
    "        print(\"Mostrando todos os parâmetros calculados para cada combinação:\")\n",
    "        print(df_ranking_sku.to_markdown(index=False, floatfmt=\".4f\"))\n",
    "        \n",
    "        print(\"\\n---\")\n",
    "        print(\"MELHOR MATCH ENCONTRADO:\")\n",
    "        print(df_ranking_sku.head(1).to_markdown(index=False, floatfmt=\".4f\"))\n",
    "        \n",
    "    print(\"=\"*60)\n",
    "    print(f\"FIM DO DEBUG PARA O SKU: {sku_desejado}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Salva o arquivo de debug específico do SKU\n",
    "    try:\n",
    "        nome_debug_excel = f\"debug_sku_{sku_desejado}.xlsx\"\n",
    "        df_ranking_sku.to_excel(nome_debug_excel, index=False)\n",
    "        print(f\"Arquivo de debug salvo em: '{nome_debug_excel}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao salvar o arquivo de debug: {e}\")\n",
    "    \n",
    "\n",
    "    # --- 4. Execução Principal ---\n",
    "# --- 4. Execução Principal ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df_estoque_dia = df_resultado.copy()\n",
    "    df_distancias_total = carregar_matriz_distancia(ARQUIVO_DISTANCIAS)\n",
    "\n",
    "    df_estoque_dia['FILIAL'] = df_estoque_dia['FILIAL'].astype(str).str.strip()\n",
    "\n",
    "    if 'REGULADOR' in df_estoque_dia.columns:\n",
    "        df_cd_estoque = df_estoque_dia.groupby('SKU', as_index=False)['REGULADOR'].first()\n",
    "        df_cd_estoque['FILIAL'] = \"CENTRO DE DISTRIBUICAO\".strip()\n",
    "        df_cd_estoque = df_cd_estoque.rename(columns={'REGULADOR': 'VOLUME_EXCESSO'})\n",
    "        \n",
    "        df_estoque_completo = pd.concat([df_estoque_dia, df_cd_estoque], ignore_index=True)\n",
    "    else:\n",
    "        print(\"Aviso: Coluna 'REGULADOR' não encontrada. O CD não será criado como fonte.\")\n",
    "        df_estoque_completo = df_estoque_dia.copy()\n",
    "\n",
    "    \n",
    "    df_ranking_global = calcular_ranking_global_nxn(\n",
    "        df_estoque_completo, \n",
    "        df_distancias_total,\n",
    "    )\n",
    "    \n",
    "    if not df_ranking_global.empty:\n",
    "        \n",
    "        exibir_debug_sku(\n",
    "            sku_desejado=\"25.34.2744-0101-TAM_2\", # <-- O SKU que você escolheu\n",
    "            df_estoque_completo=df_estoque_completo,\n",
    "            df_ranking_global=df_ranking_global\n",
    "        )\n",
    "        \n",
    "        df_melhores_matches = encontrar_melhor_match_para_todos_skus(df_ranking_global)\n",
    "        nome_arquivo = \"ranking_transferencias.xlsx\"\n",
    "        \n",
    "        try:\n",
    "            with pd.ExcelWriter(nome_arquivo, engine='openpyxl') as writer:\n",
    "                df_ranking_global.to_excel(\n",
    "                    writer, \n",
    "                    sheet_name='Ranking_Completo_NxN', \n",
    "                    index=False\n",
    "                )\n",
    "                \n",
    "                df_melhores_matches.to_excel(\n",
    "                    writer, \n",
    "                    sheet_name='Melhor_Match_por_SKU', \n",
    "                    index=False\n",
    "                )\n",
    "            \n",
    "            print(f\"Sucesso! Resultados GLOBAIS salvos em '{nome_arquivo}' com 2 abas.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao salvar o arquivo Excel global: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nCálculo do ranking N-para-N não gerou resultados. Nada foi salvo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5048a40",
   "metadata": {},
   "source": [
    "## Caminhar dos dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56337ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_desejado = '25.34.2744-0101-TAM_2'\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(ARQUIVO_JSON_FILIAIS, 'r', encoding='utf-8') as f:\n",
    "        dados_filiais = json.load(f)\n",
    "        \n",
    "    df_filiais = pd.DataFrame(dados_filiais)\n",
    "    \n",
    "    lista_nomes_filiais = df_filiais['FILIAL'].unique().tolist()\n",
    "    \n",
    "    if not lista_nomes_filiais:\n",
    "        print(\"Atenção: Nenhuma filial foi encontrada no arquivo JSON.\")\n",
    "    else:\n",
    "        print(f\"Sucesso. {len(lista_nomes_filiais)} filiais únicas encontradas.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo JSON não encontrado em '{ARQUIVO_JSON_FILIAIS}'\")\n",
    "    lista_nomes_filiais = []\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler o arquivo JSON: {e}\")\n",
    "    lista_nomes_filiais = []\n",
    "\n",
    "if lista_nomes_filiais:\n",
    "    \n",
    "    # Ex: Transforma ['Filial A', 'Filial B'] em \"('Filial A', 'Filial B')\"\n",
    "    filiais_para_query = \"','\".join(lista_nomes_filiais)\n",
    "    filiais_para_query = f\"('{filiais_para_query}')\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT SKU, FILIAL, VELOCIDADE_VENDA, ALVO, PRESENTE, TRANSITO, \n",
    "        EST_TOTAL, CONT_RUPTURA, CONT_FALTA, CONT_EXCESSO, VOLUME_EXCESSO, REGULADOR,\n",
    "        EST_DISP\n",
    "        FROM {TABELA_BIGQUERY}\n",
    "        WHERE FILIAL IN {filiais_para_query}\n",
    "        AND DATA = '{DATA_ANALISE}'\n",
    "        AND SKU = '{sku}'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Buscar os dados ---\n",
    "        \n",
    "        print(\"Executando consulta no BigQuery...\")\n",
    "        df_resultado = tableToPandas(query, 'planejamento-animale-292719', cred)\n",
    "        \n",
    "        print(\"\\n--- Resultado da Consulta ---\")\n",
    "        if df_resultado.empty:\n",
    "            print(\"A consulta não retornou dados.\")\n",
    "        else:\n",
    "            print(df_resultado)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro ao executar a consulta no BigQuery: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nAnálise não executada pois nenhuma filial foi carregada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425ee0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12e9be4",
   "metadata": {},
   "source": [
    "## Simulação de um SKU ao longo de dias\n",
    "Nesta seção simulamos o progresso de um único SKU, dia a dia, aplicando decisões de transferência e registrando cada decisão em um log que pode ser persistido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf943fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros da simulação\n",
    "sku_simulado = \"25.34.2744-0101-TAM_2\"  # SKU alvo\n",
    "dias_de_simulacao = 8                  # Quantidade de dias para simular\n",
    "max_transferencias_por_dia = 100         # Limite de decisões por dia para este SKU\n",
    "considerar_consumo = True              # Se True, consome estoque diariamente pela velocidade de venda\n",
    "fator_consumo = 1.0                    # Multiplicador do consumo diário baseado em VELOCIDADE_VENDA\n",
    "SAVE_DECISOES_EM_EXCEL = True          # Exporta log das decisões para Excel local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9627392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recalcular_metricas_estado(df_estado):\n",
    "    \"\"\"Recalcula métricas básicas do estado (por linha) após consumo/transferências.\n",
    "    - VOLUME_EXCESSO = max(0, EST_DISP - ALVO)\n",
    "    - DEMANDA_LIQUIDA = max(0, ALVO - EST_DISP)\n",
    "    - CONT_RUPTURA = 1 se EST_DISP == 0, senão 0\n",
    "    - CONT_FALTA = 1 se EST_DISP < ALVO, senão 0\n",
    "    \"\"\"\n",
    "    df_estado = df_estado.copy()\n",
    "    for col in [\"EST_TOTAL\",\"ALVO\",\"VELOCIDADE_VENDA\"]:\n",
    "        if col in df_estado.columns:\n",
    "            df_estado[col] = pd.to_numeric(df_estado[col], errors=\"coerce\").fillna(0)\n",
    "    df_estado[\"VOLUME_EXCESSO\"] = (df_estado[\"EST_DISP\"] - df_estado[\"ALVO\"]).clip(lower=0)\n",
    "    df_estado[\"DEMANDA_LIQUIDA\"] = (df_estado[\"ALVO\"] - df_estado[\"EST_DISP\"]).clip(lower=0)\n",
    "    df_estado[\"CONT_RUPTURA\"] = (df_estado[\"EST_DISP\"] == 0).astype(int)\n",
    "    df_estado[\"CONT_FALTA\"] = ((df_estado[\"EST_DISP\"] < df_estado[\"ALVO\"]) & (df_estado[\"CONT_RUPTURA\"] == 0)).astype(int)\n",
    "    return df_estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simular_sku_ao_longo_dos_dias(\n",
    "    df_estado_inicial,\n",
    "    df_distancias,\n",
    "    sku,\n",
    "    dias,\n",
    "    considerar_consumo,\n",
    "    fator_consumo,\n",
    "    max_transferencias_por_dia,\n",
    "    data_base,\n",
    "    verbose,\n",
    "):\n",
    "    df_estado = df_estado_inicial.copy()\n",
    "    df_estado = df_estado[df_estado[\"SKU\"] == sku].copy()\n",
    "    if df_estado.empty:\n",
    "        raise ValueError(f\"SKU '{sku}' não encontrado no estado inicial.\")\n",
    "    df_estado = _recalcular_metricas_estado(df_estado)\n",
    "    \n",
    "    # Estruturas de saída\n",
    "    registros_estado = []\n",
    "    registros_decisoes = []\n",
    "    data0 = pd.to_datetime(data_base)\n",
    "    \n",
    "    for dia in range(1, dias + 1):\n",
    "        data_simulada = (data0 + pd.Timedelta(days=dia-1)).date().isoformat()\n",
    "        # 1) Consumo diário\n",
    "        if considerar_consumo and \"VELOCIDADE_VENDA\" in df_estado.columns:\n",
    "            consumo = np.floor(df_estado[\"VELOCIDADE_VENDA\"] * fator_consumo)\n",
    "            df_estado[\"EST_DISP\"] = (df_estado[\"EST_DISP\"] - consumo).clip(lower=0)\n",
    "            \n",
    "        # Recalcula métricas após consumo\n",
    "        df_estado = _recalcular_metricas_estado(df_estado)\n",
    "        # csv estados\n",
    "        df_estado.to_excel(f'estado_dia_{dia}.xlsx', index=False)\n",
    "        df_rank = calcular_ranking_global_nxn(df_estado, df_distancias)\n",
    "        if df_rank is None or df_rank.empty:\n",
    "            if verbose:\n",
    "                print(f\"[Dia {dia}] Sem pares de transferência.\")\n",
    "            # Snapshot do estado\n",
    "            df_snap = df_estado.copy()\n",
    "            df_snap[\"DATA_SIMULADA\"] = data_simulada\n",
    "            df_snap[\"DIA\"] = dia\n",
    "            registros_estado.append(df_snap)\n",
    "            continue\n",
    "        \n",
    "        df_rank_sku = df_rank[df_rank['SKU'] == sku].copy()\n",
    "        df_rank_sku = df_rank_sku[df_rank_sku['QTD_A_TRANSFERIR'] > 0]\n",
    "        df_rank_sku = df_rank_sku.sort_values('RANKING_TRANSFERENCIA', ascending=False)\n",
    "        \n",
    "        transferencias_aplicadas = 0\n",
    "        for _, linha in df_rank_sku.iterrows():\n",
    "            if transferencias_aplicadas >= int(max_transferencias_por_dia):\n",
    "                break\n",
    "            origem = linha['FILIAL_FONTE']\n",
    "            destino = linha['FILIAL_DESTINO']\n",
    "            qtd = linha['QTD_A_TRANSFERIR']\n",
    "            \n",
    "            idx_origem = df_estado.index[df_estado['FILIAL'] == origem].tolist()\n",
    "            idx_dest = df_estado.index[df_estado['FILIAL'] == destino].tolist()\n",
    "            if not idx_origem or not idx_dest:\n",
    "                continue\n",
    "            \n",
    "            i_o = idx_origem[0]\n",
    "            i_d = idx_dest[0]\n",
    "            # Origem perde\n",
    "            df_estado.at[i_o, 'EST_DISP'] = max(0, df_estado.at[i_o, 'EST_DISP'] - qtd)\n",
    "            # Destino ganha\n",
    "            df_estado.at[i_d, 'EST_DISP'] = df_estado.at[i_d, 'EST_DISP'] + qtd\n",
    "            # Recalcula métricas após a transferência\n",
    "            df_estado = _recalcular_metricas_estado(df_estado)\n",
    "            \n",
    "            # Log da decisão\n",
    "            registros_decisoes.append({\n",
    "                'DATA_SIMULADA': data_simulada,\n",
    "                'DIA': dia,\n",
    "                'SKU': sku,\n",
    "                'FILIAL_FONTE': origem,\n",
    "                'FILIAL_DESTINO': destino,\n",
    "                'QTD_TRANSFERIDA': qtd,\n",
    "                'RANKING_TRANSFERENCIA': float(linha.get('RANKING_TRANSFERENCIA', 0)),\n",
    "                'DEMANDA_LIQUIDA_DESTINO': float(linha.get('DEMANDA_LIQUIDA', 0)),\n",
    "                'VOLUME_EXCESSO_ORIGEM': float(linha.get('VOLUME_EXCESSO', 0)),\n",
    "                'Distancia_km': float(linha.get('Distancia_km', 0)),\n",
    "                'LEADTIME': float(linha.get('LEADTIME', 0)),\n",
    "                'CUSTO_FRETE': float(linha.get('CUSTO_FRETE', 0)),\n",
    "            })\n",
    "            transferencias_aplicadas += 1\n",
    "        \n",
    "        # 4) Snapshot do estado ao fim do dia\n",
    "        df_snap = df_estado.copy()\n",
    "        df_snap[\"DATA_SIMULADA\"] = data_simulada\n",
    "        df_snap[\"DIA\"] = dia\n",
    "        registros_estado.append(df_snap)\n",
    "        \n",
    "    df_estado_com_dias = pd.concat(registros_estado, ignore_index=True) if registros_estado else pd.DataFrame()\n",
    "    \n",
    "    df_decisoes = pd.DataFrame(registros_decisoes) if registros_decisoes else pd.DataFrame(columns=[\n",
    "        'DATA_SIMULADA','DIA','SKU','FILIAL_FONTE','FILIAL_DESTINO','QTD_TRANSFERIDA',\n",
    "        'RANKING_TRANSFERENCIA','DEMANDA_LIQUIDA_DESTINO','VOLUME_EXCESSO_ORIGEM',\n",
    "        'Distancia_km','LEADTIME','CUSTO_FRETE'\n",
    "    ])\n",
    "    return df_estado_com_dias, df_decisoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_estoque_dia = df_resultado.copy()\n",
    "    \n",
    "    if 'REGULADOR' in df_estoque_dia.columns:\n",
    "        df_cd_estoque = df_estoque_dia.groupby('SKU', as_index=False)['REGULADOR'].first()\n",
    "        df_cd_estoque['FILIAL'] = \"CENTRO DE DISTRIBUICAO\".strip()\n",
    "        df_cd_estoque = df_cd_estoque.rename(columns={'REGULADOR': 'EST_DISP'})\n",
    "        df_cd_estoque['ALVO'] = 0\n",
    "        df_estado_inicial = pd.concat([df_estoque_dia, df_cd_estoque], ignore_index=True)\n",
    "    else:\n",
    "        df_estado_inicial = df_estoque_dia.copy()\n",
    "    \n",
    "    try:\n",
    "        _ = df_distancias_total\n",
    "    except NameError:\n",
    "        df_distancias_total = carregar_matriz_distancia(ARQUIVO_DISTANCIAS)\n",
    "    \n",
    "    # 4) Roda simulação\n",
    "    df_estado_por_dia, df_log_decisoes = simular_sku_ao_longo_dos_dias(\n",
    "        df_estado_inicial,\n",
    "        df_distancias_total,\n",
    "        sku=sku_simulado,\n",
    "        dias=int(dias_de_simulacao),\n",
    "        considerar_consumo=bool(considerar_consumo),\n",
    "        fator_consumo=float(fator_consumo),\n",
    "        max_transferencias_por_dia=int(max_transferencias_por_dia),\n",
    "        data_base=DATA_ANALISE,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \n",
    "    print(f\"Decisões registradas: {len(df_log_decisoes)}\")\n",
    "    display(df_log_decisoes.head(10))\n",
    "    \n",
    "    # 5) Persistências opcionais\n",
    "    if SAVE_DECISOES_EM_EXCEL:\n",
    "        nome_xlsx = f\"decisoes_simuladas_{sku_simulado}.xlsx\"\n",
    "        with pd.ExcelWriter(nome_xlsx, engine='openpyxl') as writer:\n",
    "            df_log_decisoes.to_excel(writer, sheet_name='decisoes', index=False)\n",
    "            df_estado_por_dia.to_excel(writer, sheet_name='estado_por_dia', index=False)\n",
    "        print(f\"Arquivo salvo: {nome_xlsx}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro na simulação: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
